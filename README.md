# Muyan-TTS

<p align="center">
Muyan-TTS <a href="https://huggingface.co/MYZY-AI/Muyan-TTS">ðŸ¤—</a>&nbsp; | Muyan-TTS-SFT <a href="https://huggingface.co/MYZY-AI/Muyan-TTS-SFT">ðŸ¤—</a>&nbsp; | &nbsp;<a href="">Technical Report</a> &nbsp;&nbsp;
</p>

Muyan-TTS is a trainable TTS model designed for podcast applications within a $50,000 budget, which is pre-trained on over 100,000 hours of podcast audio data, enabling zero-shot TTS synthesis with high-quality voice generation. Furthermore, Muyan-TTS supports speaker adaptation with dozens of minutes of target speech, making it highly customizable for individual voices.

## ðŸ”¥ðŸ”¥ðŸ”¥ News!!

* April 28, 2025: ðŸ‘‹ We release the zero-shot TTS model weights of [Muyan-TTS](https://huggingface.co/MYZY-AI/Muyan-TTS).
* April 28, 2025: ðŸ‘‹ We release the few-shot TTS model weights of [Muyan-TTS-SFT](https://huggingface.co/MYZY-AI/Muyan-TTS-SFT), which is trained based on [Muyan-TTS](https://huggingface.co/MYZY-AI/Muyan-TTS) with dozens of minutes of a single speaker's speech.
* April 28, 2025: ðŸ‘‹ We release the training code from the base model to the SFT model for speaker adaptation.
* April 28, 2025: ðŸ‘‹ We release the [technical report]() of Muyan-TTS.

## Summary

![Framework](assets/framework.png)
Framework of Muyan-TTS. Left is an LLM that models the parallel corpus of text (in blue) and audio (in green) tokens. Right is a SoVITS model that decodes the generated audio tokens, as well as phonemes and speaker embeddings, into the audio waveform.

![Pipeline](assets/pipeline.png)
Data processing pipeline. The final dataset comprises over 100,000 hours of high-quality speech and corresponding transcriptions, forming a robust parallel corpus suitable for TTS training in long-form audio scenarios such as podcasts.

| Training Cost   | Data Processing   | Pre-training of LLM| Training of Decoder | Total |
|-------|-------|-------|-------|-------|
| in GPU Hours   | 60K(A10)   | 19.2K(A100)| 1.34K(A100) | - |
| in USD   | $30K   | $19.2K| $1.34K | $50.54K |

Training costs of Muyan-TTS, assuming the rental price of A10 and A100 in GPU hour is $0.5 and $1, respectively.

## Demo

https://github.com/user-attachments/assets/a20d407c-15f8-40da-92b7-65e92e4f0c06

The three audios in the "Base model" column and the first audio in the "SFT model" column are synthesized by the open-sourced Muyan-TTS and Muyan-TTS-SFT, respectively. The last two audios in the "SFT model" column are generated by the SFT models trained separately on the base model, which are not open for use.

## Install
Clone & Install
```sh
git clone https://github.com/MYZY-AI/Muyan-TTS.git
cd Muyan-TTS

conda create -n muyan-tts python=3.10 -y
conda activate muyan-tts
make build
```

Model Download
| Models   | Links   |
|-------|-------|
| Muyan-TTS   | [huggingface](https://huggingface.co/MYZY-AI/Muyan-TTS) \| [modelscope](https://modelscope.cn/models/MYZY-AI/Muyan-TTS)   |
| Muyan-TTS-SFT   | [huggingface](https://huggingface.co/MYZY-AI/Muyan-TTS-SFT) \| [modelscope](https://modelscope.cn/models/MYZY-AI/Muyan-TTS-SFT)   |

Using Muyan-TTS as an example:
```py
from modelscope import snapshot_download
model_path = "pretrained_models/Muyan-TTS"
cnhubert_model_path = "pretrained_models/chinese-hubert-base"
try:
    snapshot_download('MYZY-AI/Muyan-TTS', local_dir=model_path)
    snapshot_download('pengzhendong/chinese-hubert-base', local_dir=cnhubert_model_path)
    print(f"Model downloaded successfully to {model_path}")
except Exception as e:
    print(f"Error downloading model: {str(e)}")
    
    
# Or you can try to install from huggingface
from huggingface_hub import snapshot_download
try:
    snapshot_download('MYZY-AI/Muyan-TTS', local_dir=model_path)
    snapshot_download('TencentGameMate/chinese-hubert-base', local_dir=cnhubert_model_path)
    print(f"Model downloaded successfully to {model_path}")
except Exception as e:
    print(f"Error downloading model: {str(e)}")
```
To download Muyan-TTS-SFT, simply replace Muyan-TTS with Muyan-TTS-SFT in model_path and repo_id.

## Acknowledgment

The model is trained base on [Llama-3.2-3B](https://huggingface.co/meta-llama/Llama-3.2-3B).

We borrow a lot of code from [GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS).

We borrow a lot of code from [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory).
